---
title: "Bay Area Bike Rental Operation Research - Analysis of Bicycle Trip and Weather Patterns"
author: "Papiha Joharapurkar (Group 5)"
date: "2022-07-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(readr)
library(funModeling)
library(tidyverse)
library(Hmisc)
library(plyr)
library(dplyr)
```

**Introduction**  
This project features the thorough exploration of the San Francisco Bay Area Bike Share dataset. This dataset provides details on quick, easy and affordable bike trips around the San Francisco Bay Area. Our goal was to explore several questions regarding to bike-patterns and weather-patterns, however we mainly focused our efforts on developing a predictive model that would be able to predict the number of bikes leaving each station and being returned to each station. 

**Exploratory Data Analysis for Trip Data**  
*First approach to the data*   
```{r glimpse, include=FALSE}
trip_data <- read_csv("trip.csv")
#### EDA for trip.data ####
# Step 1: First approach to data

glimpse(trip_data)
```

In the first approach to the “trip.csv” data set, the “glimpse” function was used to obtain an overview of the data. The data set includes a total of `r nrow(trip_data)` observation with `r length(colnames(trip_data))` variables including: `r colnames(trip_data)` 

```{r status, include=FALSE}
status(trip_data)
```
The “status” function was then used which indicated that “zip_code” was the only variable with missing values. The zip code variable had `r sum(is.na(trip_data$zipcode))` (`r  sum(is.na(trip_data$zip_code))/nrow(trip_data) * 100`% of total) missing values and 50 values equal to zero or 0.0153% of total. Since these values were less than 20% missing, they were not problematic and therefore were not removed. Moreover, the data types for each variable were obtained. All variables were set to the correct data type except for start and end dates which were coded as characters. Start and end dates will need to be changed to a date format at a later time. In addition, there were `r length(unique(trip_data$start_station_id))` unique start and end station ids, however, `r length(unique(trip_data$start_station_name))` unique start and end station names.

```{r processing_data, include=FALSE}
# Looking at unique values in start station name to identify duplicates
unique(sort(trip_data$start_station_name))
# noticed "Post at Kearney" and "Post at Kearny" as well as "Washington at Kearney" and "Washington at Kearny"

# Looking at unique values in end station name to look for duplicates
unique(sort(trip_data$end_station_name))
# "Post at Kearney" and "Post at Kearny" and "Washington at Kearney" and "Washington at Kearney"

# Fixing misspelled station names 
trip_data$start_station_name[trip_data$start_station_name == "Post at Kearny"] <- "Post at Kearney"
trip_data$start_station_name[trip_data$start_station_name == "Washington at Kearny"] <- "Washington at Kearney"

trip_data$end_station_name[trip_data$end_station_name == "Post at Kearny"] <- "Post at Kearney"
trip_data$end_station_name[trip_data$end_station_name == "Washington at Kearny"] <- "Washington at Kearney"

# Found "Broadway at Main" and "Stanford in Redwood City" are both coded under station ID 80
# Combining them into one station name 
trip_data$start_station_name[trip_data$start_station_name == "Broadway at Main"] <- "Stanford in Redwood City"
trip_data$end_station_name[trip_data$end_station_name == "Broadway at Main"] <- "Stanford in Redwood City"

# Found "San Jose Government Center" and "Santa Clara County Civic Center" are both coded under station ID 25
# Combining them into one station name 
trip_data$start_station_name[trip_data$start_station_name == "San Jose Government Center"] <- "Santa Clara County Civic Center"
trip_data$end_station_name[trip_data$end_station_name == "San Jose Government Center"] <- "Santa Clara County Civic Center"

status(trip_data)

# Step 3: Analyzing numerical variables - plot_num(trip_data)

# Runs for all numerical/integer variables automatically
profiling_num(trip_data$duration)
describe(trip_data$duration)

# Find the number of cancelled trips (<2min) and remove from data set 

# Filter rows more than 120s 
trip_clean <- trip_data %>%
  filter(duration >= 120)

# removed 2,499 trips

# Evaluating the outliers in "duration"

iqr_trip <- IQR(trip_clean$duration)
# 404

Q1 <- quantile(trip_clean$duration, .25)
Q3 <- quantile(trip_clean$duration, .75)

# Assigning an upper and lower range
up <- 1.5*iqr_trip + Q3 # Upper Range  

low <- 1.5*iqr_trip - Q1 # Lower Range

# trip_clean = 323,840 obs
trip_clean2 <- trip_clean

# Assigning any values higher and upper lower limits to be the calculated upper and lower limits to prevent data loss
trip_clean2$duration[trip_clean2$duration > up] <- up 
trip_clean2$duration[trip_clean2$duration < low] <- low

# trip_clean2 = 65,195 outliers were assigned as upper and lower limits instead of removing

# Plot histogram of the duration in seconds 
hist(trip_clean2$duration, main = "Histogram of Trip Duration", xlab = "Trip Duration in Seconds")

# Step 4: Analyzes numerical and categorical at the same time - 

describe(trip_clean2$duration)
describe(trip_clean2)

# Check min and max values (outliers)
# Check Distributions (same as before)

# Saving trip_clean2 as an RDS file
saveRDS(trip_clean2, "trip_clean2.rds")

```
This finding prompted a deeper analysis of the start and end station names to search for duplicates or misspelled station names. Using the function “unique” two misspelled station names were identified at first glance: "Washington at Kearny" and “Post at Kearny" with the correct spelling being “Kearney”. To fix this issue, the incorrectly spelled stations names were recoded with the correct spelling. Upon a closer examination of the data set, it was observed that “San Jose Government Center" and "Santa Clara County Civic Center" are both coded under station ID 25. In addition, "Broadway at Main” and "Stanford in Redwood City" were both coded under station ID 80. As "Broadway at Main” and “San Jose Government Center" stations are not included in the “station.csv” data set, they were recoded to "Stanford in Redwood City" and "Santa Clara County Civic Center" by their respective corresponding station IDs as it was assumed the names were entered incorrectly by error. The “status” function was then used again to confirm there were now `r length(unique(trip_clean2$start_station_id))` unique stations IDs and `r length(unique(trip_clean2$start_station_name))` unique station (starting and ending) names.

*Analyzing categorical variables*  
Analysis of categorical variables using the “freq” function from the “funModelling” R package examined the frequency in which starting and ending stations were seen in trip indicated the top 10 most frequent start stations in data to be: `r head(freq(trip_clean2$start_station_name), 10)$var` (Table 1). The top 10 ending stations were similar: `r tail(freq(trip_clean2$start_station_name), 10)$var` (Table 2).

## Table 1
```{r table_setup, include=FALSE}
output <- freq(trip_clean2$start_station_name)
```

```{r table_1, echo=FALSE}
output %>% head(10)
```

Table 1: Ten most frequent starting stations overall. Number of total rides left from each station with the percent of total ride left from each station.

## Table 2
```{r table_setup2, include=FALSE}
output_2 <- freq(trip_clean2$end_station_name)
```

```{r table_2, echo=FALSE}
output_2 %>% head(10)
```
Table 2: Ten most frequent ending stations overall. Number of total rides arrived at each station with the percent of total ride arrived at each station.

In addition, analysis of the subscription type found that `r freq(trip_data$subscription_type)$percentage[1]`% of rides are by “Subscribers” and `r freq(trip_data$subscription_type)$percentage[2]`% of rides are by “Customers”, those without a subscription (Figure 1). 

```{r plot_setup, echo=FALSE, warning=FALSE}
plot_1 <- freq(trip_data$subscription_type)
```
Figure 1: Subscription types.


*Analyzing numerical variables and addressing outliers*
```{r trip_dur, warning=FALSE, include=FALSE}
describe(trip_data$duration)  
```

Analysis of numerical variables using the “describe” function from the “Hmisc” R package was done to obtain information about the trip durations. The mean value of trip duration was of trips in the dataset was 1131.967 sec, with the five highest durations being 644 771, 715 339, 716 480, 720 454, and 1 727 040 seconds long and the five lowest durations all being approximately 60 seconds or less. Here, trips that were less than 2 minutes (120 seconds long) were removed from the data set using the filter function from the “tidyverse” package; about 2,499 observations were removed from the dataset after completing this step. 

Outliers were identified using the equation 1.5xIQR + Q3 for identifying the upper limits and 1.5xIQR - Q1 for identifying the lower limits. There were approximately 65,195 outliers if the upper and lower limits were to be removed. To prevent loss of a massive number of data points the outliers were identified and reassigned to be the upper and lower limits as opposed to removing them entirely. A histogram of duration trip frequency was created to examine the distribution and to check for any extreme skewedness (Figure 2). Using the “describe” function from the “ Hmisc” package a final check of the data was done to ensure outliers had been addressed. After modifying outliers to be either upper or lower limits, the new mean of trip duration was 598.9 seconds. The modified trip data set was named “trip_clean2” and saved as a RDS file for later use.

```{r hist_trip_data, echo=FALSE, warning=FALSE}
hist(trip_clean2$duration, main = "Histogram of Trip Duration", xlab = "Trip Duration in Seconds")  
```
Figure 2: Histogram of trip durations in seconds. Note frequencies at each end of the range are large due to the reassignment of outliers to upper and lower limits.


Exploratory Data Analysis for Weather Data 

First approach to the data 

```{r weather_glimpse, include=FALSE}
#Uploading weather.dataset and assigning to weather_df object
weather_df <- read.csv("weather.csv")

#Overview on variables from each column and few observations
glimpse(weather_df)

#Profiling the data input 
status(weather_df)

#performing necessary transformations before visualization
weather_df_1 <- weather_df %>% 
  #changing date-column from character to as.date type 
  mutate(date = as.POSIXct(date, format="%d/%m/%y")) %>%
  #replacing T-values in precipitation column with 0 
  mutate (precipitation_inches = str_replace(precipitation_inches, pattern="T", replacement="0")) %>% 
  #changing precipitation from character to numeric  
  mutate (precipitation_inches = as.numeric(precipitation_inches)) %>%
  #changing cloud cover variable from character to factor  
  mutate (cloud_cover = as.factor(cloud_cover)) %>%
  #changing events to character type 
  mutate (events = as.character(events)) %>%
  #recoding "" in events to NA 
  mutate (events = na_if(x=events, y="")) %>%
  #changing events to be coded as factor
  mutate (events = as.factor(events)) %>%
  #changing zipcode to be coded as factor
  mutate (zip_code = as.factor(as.character(zip_code))) %>%
  #changing city to be coded as factor 
  mutate (city = as.factor(city)) %>% 
  #changing max_visibility_miles to be coded as numeric 
  mutate (max_visibility_miles = as.numeric(max_visibility_miles)) %>% 
  #changing mean_visibility_miles to be coded as numeric 
  mutate (mean_visibility_miles = as.numeric(mean_visibility_miles)) %>% 
  #changing max_wind_Speed_mph to be coded as numeric 
  mutate (max_wind_Speed_mph = as.numeric(max_wind_Speed_mph)) %>% 
  #changing max_gust_speed_mph to be coded as numeric 
  mutate (max_gust_speed_mph = as.numeric(max_gust_speed_mph)) %>%
  #changing mean_wind_speed_mph to be coded as numeric 
  mutate (mean_wind_speed_mph = as.numeric(mean_wind_speed_mph)) %>% 
  #changing min_visibility_miles to be coded as numeric 
  mutate (min_visibility_miles = as.numeric(min_visibility_miles)) %>%
  #changing max_temperature_f to be coded as numeric 
  mutate (max_temperature_f = as.numeric(max_temperature_f)) %>% 
  #changing mean_temperature_f to be coded as numeric 
  mutate (mean_temperature_f = as.numeric(mean_temperature_f)) %>% 
  #changing min_temperature_f to be coded as numeric 
  mutate (min_temperature_f = as.numeric(min_temperature_f)) 

str(weather_df_1)
```
To initiate our exploration of the weather.csv file, the “glimpse” function from the dplyr package was used to obtain an overview of all the variables from the weather dataset. In this primary step, the following details were noted: 
The date column was formatted in character-form instead of as date form, which necessitated a modification to the latter form. In addition, the max_temperature_f, mean_temperature_f and min_temperature_f variables, along with the max_visibility_miles, mean_visibility_miles, min_visibility_miles variables, and the max_wind_Speed_mph, mean_wind_speed_mph, max_gust_speed_mph variables were provided in integer form. These would need to be coded to numeric form for future analyses, such as correlation plots. Moreover, the precipitation (inches) was incorrectly coded as characters instead of integers, due to the fact that there were a few values coded as “T”. This value encodes “trace” for trace-amounts of precipitation, and would need to be changed to 0. The cloud-cover variable seems to be coded as an integer but could be coded as a factor as there are different categories of cloud-cover. In addition, the events variable seem to be properly coded as characters, however the output also indicated that there are some variables coded as “ “ which would need to be changed to NA. The zipcode variable is also correctly coded as an integer, but should be coded as a factor. Based on this initial examination, the variables were recoded and reformatted before performing any of the future steps of the EDA. 

*Analyzing categorical variables*
The next approach to the exploratory analysis involved performing an assessment of the categorical data through the “freq” function. There were only a few categorical variables assessed, these encompassed the cloud_cover, events, zip_code and city variables and the most relevant plots are shown here. The output revealed that there were 9 levels of the cloud_cover variable, ranging in frequency with 0-cloud cover being the most frequent and 8-cloud_cover category as being the least frequent as shown in Figure 3A. In addition, the events variable indicated that 80.71% (representing 1473 data values) of the data was composed of NA-values, with the next most frequent events composing of rain and fog. Lastly, there were 5 levels associated with the cities, related to the 5 levels of zipcodes, which are evenly distributed in frequency, as shown by Figure 3B. 
```{r weather_categorical, echo=FALSE}
#analyzing categorical data 
#figure out how to 
output_weather <- freq(weather_df_1)
```

Figure 3: Assessment of Categorical Variables. A) Frequency of Weather Events (Left) B) Frequency of Dates for Each City (Right)

*Analyzing numerical variables *
After assessing the categorical variables, the variables remaining were numerical in form, and were thus explored through the plot_num function. For this function, barplots were provided for all the numerical variables, which helped us develop initial insights into each of variables as can be seen in Figure 4. The minimum-visibility (miles), maximum-gust-speed (mph) variables, along with max_gust_speed_mph and precipitation_inches variables show relatively skewed and unbalanced distributions which can be attributed to the presence of outliers that would need to be removed, supporting previous analyses. The remaining numerical variables seem to have a relatively normal distribution, without any discerning outliers. 

```{r figure_4, echo=FALSE}
#analyzing categorical data 
plot_num(weather_df_1)
```
Figure 4: Assessment of Numerical Variables. The minimum-visibility (miles), maximum-gust-speed (mph), max_gust_speed_mph and precipitation_inches variables display skewed-distributions.

After plotting the numerical variables, the profiling-num function was performed to obtain an understanding of each variable’s distribution and range. This function demonstrated that there is a high standard deviation for the max_temperature_f, mean_temperature_f, min_temperature_f, max_wind_Speed_mph and max_gust_speed_mph variables. In addition, the variation coefficient demonstrated that the precipitation_inches variable is associated with more variance as opposed to the remaining variables that are centered around the mean, inferring less accuracy associated with this variable if it were to be chosen as a possible predictor. The skewness metric informs on the measure of asymmetry, and this function demonstrated that the variables of max_visibility_miles, mean_visibility_miles, max_wind_Speed_mph, max_gust_speed_mph and precipitation_inches variables have greater skewness-values and therefore greater likelihood of observing outliers in these variables. The kurtosis variable describes the distribution for the tails, where higher number indicates presence of outliers, and this was demonstrated by the higher values shown for the max_visibility_miles, mean_visibility_miles, max_wind_Speed_mph, max_gust_speed_mph and precipitation_inches variables. There was also a high IQR range for the max_temperature_f, mean_temperature_f, and min_temperature_f variables obtained. 

```{r describe, echo=FALSE}
#full univariate analysis being performed 
funModeling::profiling_num(weather_df_1)

#provides summary on both numerical and categorical data 
describe(weather_df_1)

#writing modified_weaher_data into weather_transform csv file
saveRDS(weather_df_1, "weather_transform.rds")
```
The describe function was used to obtain an overall overview of both the numerical and categorical variables. The date-column has `r describe(weather_df_1)$date[[4]][[3]]` unique values but `r describe(weather_df_1)$date[[4]][[1]]` dates available, with the remaining `r describe(weather_df_1)$date[[4]][[2]]` values being missing values and representing 60.5% of the date-data. These values range from 2020-01-10 to 2020-12-12. Since this date-data is being used for combining with the trip-data based on date, values with missing dates will be removed. The max_temperature_f column has `r describe(weather_df_1)$max_temperature_f[[4]][[3]]` unique values, ranging from `r describe(weather_df_1)$max_temperature_f[[5]][[1]][1]` to `r describe(weather_df_1)$max_temperature_f[[5]][[1]][46]`. For the mean_temperature_f variable, there are `describe(weather_df_1)$mean_temperature_f[[4]][[3]]` distinct values ranging from `r describe(weather_df_1)$mean_temperature_f[[5]][[1]][[1]]` to `r describe(weather_df_1)$mean_temperature_f[[5]][[1]][[37]]`, and similarly, there are `r describe(weather_df_1)$min_temperature_f[[4]][[3]]` distinct values for the min_temperature_f variable, ranging from `describe(weather_df_1)$min_temperature_f[[5]][[1]][[1]]` to `r describe(weather_df_1)$min_temperature_f[[5]][[1]][[37]]`. The max_visibility_miles has `r describe(weather_df_1)$max_visibility_miles[[4]][[2]]` missing values, and `r describe(weather_df_1)$max_visibility_miles[[4]][[3]]` distinct values ranging from `r describe(weather_df_1)$max_visibility_miles[[5]][[1]][[1]]` to `r describe(weather_df_1)$max_visibility_miles[[5]][[1]][[9]]`. This variable was also shown to have many outliers, which will need to be removed. The related column of mean_visibility_miles has `r describe(weather_df_1)$mean_visibility_miles[[4]][[2]]` missing values, and `r describe(weather_df_1)$mean_visibility_miles[[4]][[3]]` distinct values ranging from `r describe(weather_df_1)$mean_visibility_miles[[5]][[1]][[1]]` to `r describe(weather_df_1)$mean_visibility_miles[[5]][[1]][[17]]`, the higher values representing outlier-values will also need to be removed. The min_visibility_miles variable has `r describe(weather_df_1)$min_visibility_miles[[4]][[2]]` missing values and `describe(weather_df_1)$min_visibility_miles[[4]][[3]]` distinct values ranging from `r describe(weather_df_1)$min_visibility_miles[[5]][[1]][[1]]` to `r describe(weather_df_1)$min_visibility_miles[[5]][[1]][[13]]`, but this column does not have any outliers as shown by previous analyses. The max_wind_Speed_mph variable has no missing values, but `r describe(weather_df_1)$max_wind_Speed_mph[[4]][[3]]` distinct values ranging from `r describe(weather_df_1)$max_wind_Speed_mph[[5]][[1]][[1]]` to `r describe(weather_df_1)$max_wind_Speed_mph[[5]][[1]][[34]]`, and this variable has been noted to contain outliers, which will be removed. The mean_wind_speed_mph variable has no missing values, but `r describe(weather_df_1)$mean_wind_speed_mph[[4]][[3]]` distinct values ranging from `r describe(weather_df_1)$mean_wind_speed_mph[[5]][[1]][[1]]` to `r describe(weather_df_1)$mean_wind_speed_mph[[5]][[1]][[20]]`, but no presence of outliers. The max_gust_speed_mph variable has `r describe(weather_df_1)$max_gust_speed_mph[[4]][[2]]` missing values, and `r  describe(weather_df_1)$max_gust_speed_mph[[4]][[3]]` distinct-events, ranging from `r describe(weather_df_1)$max_gust_speed_mph[[5]][[1]][[1]]` to `r describe(weather_df_1)$max_gust_speed_mph[[5]][[1]][[43]]`, and previous analyses indicate this variable has outliers which will be removed. For the precipitation inches variable, there are `r describe(weather_df_1)$precipitation_inches[[4]][[3]]` unique values ranging from `r describe(weather_df_1)$precipitation_inches[[5]][[1]][[1]]` to `r describe(weather_df_1)$precipitation_inches[[5]][[1]][[74]]`, but this variable has been noted to contain outlier values, which will be removed. For the cloud-cover variable, there are no missing values and `r  describe(weather_df_1)$cloud_cover[[4]][[3]]` distinct events ranging from `r describe(weather_df_1)$cloud_cover[[5]][[1]][[1]]` to `r describe(weather_df_1)$cloud_cover[[5]][[1]][[9]]`, with no discernable outliers according to previous analyses. For the event variable, there are `r describe(weather_df_1)$events[[4]][[3]]` distinct-events however with `r describe(weather_df_1)$events[[4]][[2]]` missing values. For the zip-code variable, there are `r  describe(weather_df_1)$zip_code[[4]][[2]]` missing values but `r describe(weather_df_1)$zip_code[[4]][[3]]` distinct events. This variable is also similar to the output from the city-variable, which retrieved 0 missing values but `r  describe(weather_df_1)$city[[4]][[3]]` distinct events, with both of these variables retrieving equivalent proportions for the frequency of each of the values. For the variables with missing values which are the date, max_visibility_miles, mean_visibility_miles, min_visibility_miles, max_gust_speed_mph and events variables, the missing-values were not recoded to 0 or other values such as mean/minimum/maximum as these entries instead represent events where values were simply not observed and recorded, and it would be incorrect to impute values in place of them. 

*Addressing outliers*
```{r weather_outliers, include=FALSE}
#Outlier Removal for Weather

#loading libraries
library(tidyverse)
library(dplyr)
library(lubridate)
library(stats)

#reading in weather and data, assigning to weather_df object
weather_df <- readRDS("weather_transform.rds")

#removing NA values for unavailable dates, assigning to weather_df_2
weather_df_2 <- weather_df %>% filter(!is.na(date))

#EDA indicated presence of outliers in the following variables: max_visibility_miles, 
#mean_visibility_miles, max_wind_Speed_mph, max_gust_speed_mph and precipitation_inches 

#outliers being removed based on the IQR method 
#outlier removal attempt for max_visibility_miles, indicates that both upper and lower limit are the same 
quartile_max_visibility_miles <- quantile(weather_df_2$max_visibility_miles, probs=c(.25, .75), na.rm = T)
iqr_max_visibility_miles <- IQR(weather_df_2$max_visibility_miles, na.rm=T)
upper_lim_max_visibility_miles <- quartile_max_visibility_miles[2] + 1.5*iqr_max_visibility_miles
lower_lim_max_visibility_miles <- quartile_max_visibility_miles[1] - 1.5*iqr_max_visibility_miles 
#outlier removal based on percentiles:
upper_lim_max_visibility_miles <- quantile(weather_df_2$max_visibility_miles, 0.975, na.rm=T)
lower_lim_max_visibility_miles <- quantile(weather_df_2$max_visibility_miles, 0.025, na.rm=T)

#number of lower-limit outliers recoded
sum(weather_df_2$max_visibility_miles < as.numeric(lower_lim_max_visibility_miles), na.rm=T)

#number of higher-limit outliers recoded
sum(weather_df_2$max_visibility_miles > as.numeric(upper_lim_max_visibility_miles), na.rm=T)

#recoding of both outliers 
weather_df_2 <- weather_df_2 %>% 
  mutate(max_visibility_miles = case_when(max_visibility_miles > as.numeric(upper_lim_max_visibility_miles) ~ as.numeric(upper_lim_max_visibility_miles), TRUE ~ max_visibility_miles)) %>% 
  mutate(max_visibility_miles = case_when(max_visibility_miles < as.numeric(lower_lim_max_visibility_miles) ~ as.numeric(lower_lim_max_visibility_miles), TRUE ~ max_visibility_miles))

#not removed for mean_visibility_miles due to outer and lower bounds being the same 
quartile_mean_visibility_miles <- quantile(weather_df_2$mean_visibility_miles, probs=c(.25, .75), na.rm = T)
iqr_mean_visibility_miles <- IQR(weather_df_2$mean_visibility_miles, na.rm=T)
upper_lim_mean_visibility_miles <- quartile_mean_visibility_miles[2] + 1.5*iqr_mean_visibility_miles
lower_lim_mean_visibility_miles <- quartile_mean_visibility_miles[1] - 1.5*iqr_mean_visibility_miles 
#outlier removal based on percentiles:
upper_lim_mean_visibility_miles <- quantile(weather_df_2$mean_visibility_miles, 0.975, na.rm=T)
lower_lim_mean_visibility_miles <- quantile(weather_df_2$mean_visibility_miles, 0.025, na.rm=T)

#number of lower-limit outliers recoded
sum(weather_df_2$mean_visibility_miles < as.numeric(lower_lim_mean_visibility_miles), na.rm=T)

#number of higher-limit outliers recoded
sum(weather_df_2$mean_visibility_miles > as.numeric(upper_lim_mean_visibility_miles), na.rm=T)

#recoding of outliers 
weather_df_2 <- weather_df_2 %>% 
  mutate(mean_visibility_miles = case_when(max_visibility_miles > as.numeric(upper_lim_mean_visibility_miles) ~ as.numeric(upper_lim_mean_visibility_miles), TRUE ~ mean_visibility_miles)) %>% 
  mutate(mean_visibility_miles = case_when(max_visibility_miles < as.numeric(lower_lim_mean_visibility_miles) ~ as.numeric(lower_lim_mean_visibility_miles), TRUE ~ mean_visibility_miles))


#outliers removed for max_wind_Speed_mph due to outer and lower bounds being different 
quartile_max_wind_speed_mph <- quantile(weather_df_2$max_wind_Speed_mph, probs=c(.25, .75), na.rm = T)
iqr_max_wind_Speed_mph <- IQR(weather_df_2$max_wind_Speed_mph, na.rm=T)
upper_lim_max_wind_Speed_mph <- quartile_max_wind_speed_mph[2] + 1.5*iqr_max_wind_Speed_mph
lower_lim_max_wind_Speed_mph <- quartile_max_wind_speed_mph[1] - 1.5*iqr_max_wind_Speed_mph 

#number of lower-limit outliers recoded
sum(weather_df_2$max_wind_Speed_mph < as.numeric(lower_lim_max_wind_Speed_mph), na.rm=T)

#number of higher-limit outliers recoded
sum(weather_df_2$max_wind_Speed_mph > as.numeric(upper_lim_max_wind_Speed_mph), na.rm=T)

#recoding of outliers  for max_wind_Speed_mph variable to upper IQR limit if higher-than upper limit, else recoding to lower limit 
weather_df_2 <- weather_df_2 %>%
  mutate(max_wind_Speed_mph = case_when(max_wind_Speed_mph > as.numeric(upper_lim_max_wind_Speed_mph) ~ as.numeric(upper_lim_max_wind_Speed_mph), TRUE ~ max_wind_Speed_mph)) %>% 
  mutate(max_wind_Speed_mph = case_when(max_wind_Speed_mph < as.numeric(lower_lim_max_wind_Speed_mph) ~ as.numeric(lower_lim_max_wind_Speed_mph), TRUE ~ max_wind_Speed_mph))

#outliers removed for max_gust_speed_mph due to outer and lower bounds being different 
quartile_max_gust_speed_mph <- quantile(weather_df_2$max_gust_speed_mph, probs=c(.25, .75), na.rm = T)
iqr_max_gust_speed_mph <- IQR(weather_df_2$max_gust_speed_mph, na.rm=T)
upper_max_gust_speed_mph <- quartile_max_gust_speed_mph[2] + 1.5*iqr_max_gust_speed_mph
lower_max_gust_speed_mph <- quartile_max_gust_speed_mph[1] - 1.5*iqr_max_gust_speed_mph 

#number of lower-limit outliers recoded
sum(weather_df_2$max_gust_speed_mph < as.numeric(lower_max_gust_speed_mph), na.rm=T)

#number of higher-limit outliers recoded
sum(weather_df_2$max_gust_speed_mph > as.numeric(upper_max_gust_speed_mph), na.rm=T)

#recoding of outliers  for max_gust_speed_mph variable to upper IQR limit if higher-than upper limit, else recoding to lower limit 
weather_df_2 <- weather_df_2 %>% 
  mutate(max_gust_speed_mph = case_when(max_gust_speed_mph > as.numeric(upper_max_gust_speed_mph) ~ as.numeric(upper_max_gust_speed_mph), TRUE ~ max_gust_speed_mph)) %>% 
  mutate(max_gust_speed_mph = case_when(max_gust_speed_mph < as.numeric(lower_max_gust_speed_mph) ~ as.numeric(lower_max_gust_speed_mph), TRUE ~ max_gust_speed_mph))

#outliers not removed for precipitation  due to outer and lower bounds being the same 
quartile_precipitation <- quantile(weather_df_2$precipitation_inches, probs=c(.25, .75), na.rm = T)
iqr_precipitation <- IQR(weather_df_2$precipitation_inches, na.rm=T)
upper_precipitation <- quartile_precipitation[2] + 1.5*iqr_precipitation
lower_precipitation <- quartile_precipitation[1] - 1.5*iqr_precipitation 
#outlier removal based on percentiles:
upper_precipitation <- quantile(weather_df_2$precipitation_inches, 0.975, na.rm=T)
lower_precipitation <- quantile(weather_df_2$precipitation_inches, 0.025, na.rm=T)

#number of lower-limit outliers recoded
sum(weather_df_2$precipitation_inches < as.numeric(lower_precipitation), na.rm=T)

#number of higher-limit outliers recoded
sum(weather_df_2$precipitation_inches > as.numeric(upper_precipitation), na.rm=T)

weather_df_2 <- weather_df_2 %>% 
  mutate(precipitation_inches = case_when(precipitation_inches > as.numeric(upper_precipitation) ~ as.numeric(upper_precipitation), TRUE ~ precipitation_inches)) %>% 
  mutate(precipitation_inches = case_when(precipitation_inches < as.numeric(lower_precipitation) ~ as.numeric(lower_precipitation), TRUE ~ precipitation_inches))

saveRDS(weather_df_2, "weather_no_outliers.rds")
```

The previous exploratory analyses were helpful in uncovering the variables that necessitated outlier-removal in order to ensure high accuracy of future results. Firstly, we initially removed all the available data were date-information was not available for reasons explained previously.  The method of removing outliers was consistent for many of the same variables from the trip-dataset, with some exceptions, where outliers were identified using the equation 1.5xIQR + Q3 for identifying the upper limits and 1.5xIQR - Q1 for identifying the lower limits. To start, the IQR quantile and IQR functions were applied on the variable of max_visibility_miles, but since identical values for both the upper limit and lower limit were retrieved, therefore instead, another method of outlier recoding was used. This method that was used was the percentile-method, where data values were recoded to the lower and upper limits if observation values were beyond the 2.5%  or 97.5% percentile respectively. This alternative approach allowed for the successful recoding of `r sum(weather_df_2$max_visibility_miles < as.numeric(lower_lim_max_visibility_miles), na.rm=T)` lower-limit outliers and `r sum(weather_df_2$max_visibility_miles > as.numeric(upper_lim_max_visibility_miles), na.rm=T)` for upper limit of max_visibility_miles. Similarly for the mean_visibility_miles variable, identical values for the upper limit and lower limit were retrieved, and the percentile method of outlier removal was performed. This allowed for the recoding of `r sum(weather_df_2$mean_visibility_miles < as.numeric(lower_lim_mean_visibility_miles), na.rm=T)` lower-limit values and `r sum(weather_df_2$mean_visibility_miles > as.numeric(upper_lim_mean_visibility_miles), na.rm=T)` higher-limit values. The determination of disparate values for the upper and lower limit for the variable of max_wind_Speed_mph was also successful, allowing for those outlier-values to be recoded from the dataset based on the IQR method. There were `r sum(weather_df_2$max_wind_Speed_mph < as.numeric(lower_lim_max_wind_Speed_mph), na.rm=T)` lower-limit outliers recoded and `r sum(weather_df_2$max_wind_Speed_mph > as.numeric(upper_lim_max_wind_Speed_mph), na.rm=T)` higher-limit outliers recoded. The IQR method of outlier removal was also successful for the max_gust_speed_mph variable allowing for the recoding of `r sum(weather_df_2$max_gust_speed_mph < as.numeric(lower_max_gust_speed_mph), na.rm=T)` lower-limit but `r sum(weather_df_2$max_gust_speed_mph > as.numeric(upper_max_gust_speed_mph), na.rm=T)` higher limit outliers. Finally, the method of outlier removal based on percentiles was used for the variable of precipitation_inches, allowing for `r  sum(weather_df_2$precipitation_inches < as.numeric(lower_precipitation), na.rm=T)` lower-limit but `r sum(weather_df_2$precipitation_inches > as.numeric(upper_precipitation), na.rm=T)` higher-limit outliers to be recoded.



*Outliers for Station*

```{r station_outliers, include=FALSE}
#Station Outlier Removal and the Identification of Stations not in Trip Data 

#Importing libraries
library(tidyverse)
library(dplyr)

#reading in station file 
station_df <- read.csv("station.csv")

#structure of file 
str(station_df)

#summary of file 
summary(station_df)

#determining number of unique station-names from station-file 
nrow(unique(station_df))

#reading in trip file
trip_file <- read.csv("trip.csv")
#determining number of unique station-names from trip-file
length(unique(trip_file$end_station_name))

#determining which stations have not been coded in station_file with anti_join function
#the trip_file was used as the left-file because it has greater values 
unique_stations_end <- anti_join(trip_file,station_df, by=c("end_station_name" = "name"))
#the stations not encoded in station_file were retrieved with unique function
unique(unique_stations_end$end_station_name)
```

Alongside the weather and data-files, the station file was also examined. With the structure function, the station file was found to provide many insights. To note, the id-variables were correctly coded as numeric and station name and city variables were correctly coded in character form. Additionally, the latitude and longitude variables were also correctly coded as numeric alongside the dock-count variable. However, the installation-dates were coded as characters. In order to identify any outliers in association to the main trip-file, the number of unique rows was determined, which was retrieved to be `r nrow(unique(station_df))`. After this, the number of unique stations was determined within the trip-file was determined by using the end-station-name, although this could have been replaced with start-station-name. This resulted in the total output of `r length(unique(trip_file$end_station_name))` unique values. This value’s discrepancy with the value from the station file suggested that there were 4 additional values that had been improperly coded in the trip-data file. In order to determine which station-names had been improperly coded in the trip-data, an anti-join function was applied with the trip-data and the station-file data to determine which station-names did not match with the station-data. This function found that the `r unique(unique_stations_end$end_station_name)` values had not been provided in the station-data and must have been therefore, been improperly coded in the trip-file data.       
