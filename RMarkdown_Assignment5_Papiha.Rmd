---
title: "Bay Area Bike Rental Operation Research: Analysis of Bicycle Trip and Weather Patterns"
author: "Papiha Joharapurkar (Group 5)"
date: "2022-07-13"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, include=FALSE}
library(readr)
library(funModeling)
library(tidyverse)
library(Hmisc)
library(plyr)
library(dplyr)
```

**Introduction**  
This project features the thorough exploration of the San Francisco Bay Area Bike Share dataset. This dataset provides details on quick, easy and affordable bike trips around the San Francisco Bay Area. Our goal was to explore several questions regarding to bike-patterns and weather-patterns, however we mainly focused our efforts on developing a predictive model that would be able to predict the number of bikes leaving each station and being returned to each station. 

**Exploratory Data Analysis for Trip Data**  
*First approach to the data*   
```{r glimpse, include=FALSE}
trip_data <- read_csv("trip.csv")
#### EDA for trip.data ####
# Step 1: First approach to data

glimpse(trip_data)
```

In the first approach to the “trip.csv” data set, the “glimpse” function was used to obtain an overview of the data. The data set includes a total of `r nrow(trip_clean2)` observation with `r length(colnames(trip_clean2))` variables including: `r colnames(trip_clean2)` 

```{r status, include=FALSE}
status(trip_data)
```
The “status” function was then used which indicated that “zip_code” was the only variable with missing values. The zip code variable had `r sum(is.na(trip_data$zipcode))` (`r  sum(is.na(trip_data$zip_code))/nrow(trip_data) * 100`% of total) missing values and 50 values equal to zero or 0.0153% of total. Since these values were less than 20% missing, they were not problematic and therefore were not removed. Moreover, the data types for each variable were obtained. All variables were set to the correct data type except for start and end dates which were coded as characters. Start and end dates will need to be changed to a date format at a later time. In addition, there were `r length(unique(trip_data$start_station_id))` unique start and end station ids, however, `r length(unique(trip_data$start_station_name))` unique start and end station names.

```{r unique, include=FALSE}
# Looking at unique values in start station name to identify duplicates
unique(sort(trip_data$start_station_name))
# noticed "Post at Kearney" and "Post at Kearny" as well as "Washington at Kearney" and "Washington at Kearny"

# Looking at unique values in end station name to look for duplicates
unique(sort(trip_data$end_station_name))
# "Post at Kearney" and "Post at Kearny" and "Washington at Kearney" and "Washington at Kearney"

# Fixing misspelled station names 
trip_data$start_station_name[trip_data$start_station_name == "Post at Kearny"] <- "Post at Kearney"
trip_data$start_station_name[trip_data$start_station_name == "Washington at Kearny"] <- "Washington at Kearney"

trip_data$end_station_name[trip_data$end_station_name == "Post at Kearny"] <- "Post at Kearney"
trip_data$end_station_name[trip_data$end_station_name == "Washington at Kearny"] <- "Washington at Kearney"

# Found "Broadway at Main" and "Stanford in Redwood City" are both coded under station ID 80
# Combining them into one station name 
trip_data$start_station_name[trip_data$start_station_name == "Broadway at Main"] <- "Stanford in Redwood City"
trip_data$end_station_name[trip_data$end_station_name == "Broadway at Main"] <- "Stanford in Redwood City"

# Found "San Jose Government Center" and "Santa Clara County Civic Center" are both coded under station ID 25
# Combining them into one station name 
trip_data$start_station_name[trip_data$start_station_name == "San Jose Government Center"] <- "Santa Clara County Civic Center"
trip_data$end_station_name[trip_data$end_station_name == "San Jose Government Center"] <- "Santa Clara County Civic Center"

status(trip_data)

```
This finding prompted a deeper analysis of the start and end station names to search for duplicates or misspelled station names. Using the function “unique” two misspelled station names were identified at first glance: "Washington at Kearny" and “Post at Kearny" with the correct spelling being “Kearney”. To fix this issue, the incorrectly spelled stations names were recoded with the correct spelling. Upon a closer examination of the data set, it was observed that “San Jose Government Center" and "Santa Clara County Civic Center" are both coded under station ID 25. In addition, "Broadway at Main” and "Stanford in Redwood City" were both coded under station ID 80. As "Broadway at Main” and “San Jose Government Center" stations are not included in the “station.csv” data set, they were recoded to "Stanford in Redwood City" and "Santa Clara County Civic Center" by their respective corresponding station IDs as it was assumed the names were entered incorrectly by error. The “status” function was then used again to confirm there were now `r length(unique(trip_clean2$start_station_id))` unique stations IDs and `r length(unique(trip_clean2$start_station_name))` unique station (starting and ending) names.

*Analyzing categorical variables*  
Analysis of categorical variables using the “freq” function from the “funModelling” R package examined the frequency in which starting and ending stations were seen in trip indicated the top 10 most frequent start stations in data to be: `r head(freq(trip_clean2$start_station_name), 10)$var` (Table 1). The top 10 ending stations were similar: `r tail(freq(trip_clean2$start_station_name), 10)$var` (Table 2).

## Table 1
```{r table_setup, include=FALSE}
output <- freq(trip_clean2$start_station_name)
```

```{r table_1, echo=FALSE}
output %>% head(10)
```

Table 1: Ten most frequent starting stations overall. Number of total rides left from each station with the percent of total ride left from each station.

## Table 2
```{r table_setup2, include=FALSE}
output_2 <- freq(trip_clean2$end_station_name)
```

```{r table_2, echo=FALSE}
output_2 %>% head(10)
```
Table 2: Ten most frequent ending stations overall. Number of total rides arrived at each station with the percent of total ride arrived at each station.

In addition, analysis of the subscription type found that `r freq(trip_data$subscription_type)$percentage[1]`% of rides are by “Subscribers” and `r freq(trip_data$subscription_type)$percentage[2]`% of rides are by “Customers”, those without a subscription (Figure 1). 

```{r plot_setup, echo=FALSE, warning=FALSE}
plot_1 <- freq(trip_data$subscription_type)
```
Figure 1: Subscription types.


*Analyzing numerical variables and addressing outliers*
```{r trip_dur, warning=FALSE, include=FALSE}
describe(trip_data$duration)  
```

Analysis of numerical variables using the “describe” function from the “Hmisc” R package was done to obtain information about the trip durations. The mean value of trip duration was of trips in the dataset was 1131.967 sec, with the five highest durations being 644 771, 715 339, 716 480, 720 454, and 1 727 040 seconds long and the five lowest durations all being approximately 60 seconds or less. Here, trips that were less than 2 minutes (120 seconds long) were removed from the data set using the filter function from the “tidyverse” package; about 2,499 observations were removed from the dataset after completing this step. 

```{r EDA, include=FALSE}


# Step 3: Analyzing numerical variables - plot_num(trip_data)

# Runs for all numerical/integer variables automatically
profiling_num(trip_data$duration)
describe(trip_data$duration)

# Find the number of cancelled trips (<2min) and remove from data set 

# Filter rows more than 120s 
trip_clean <- trip_data %>%
  filter(duration >= 120)

# removed 2,499 trips

# Evaluating the outliers in "duration"

iqr_trip <- IQR(trip_clean$duration)
# 404

Q1 <- quantile(trip_clean$duration, .25)
Q3 <- quantile(trip_clean$duration, .75)

# Assigning an upper and lower range
up <- 1.5*iqr_trip + Q3 # Upper Range  

low <- 1.5*iqr_trip - Q1 # Lower Range

# trip_clean = 323,840 obs
trip_clean2 <- trip_clean

# Assigning any values higher and upper lower limits to be the calculated upper and lower limits to prevent data loss
trip_clean2$duration[trip_clean2$duration > up] <- up 
trip_clean2$duration[trip_clean2$duration < low] <- low

# trip_clean2 = 65,195 outliers were assigned as upper and lower limits instead of removing

# Plot histogram of the duration in seconds 
hist(trip_clean2$duration, main = "Histogram of Trip Duration", xlab = "Trip Duration in Seconds")

# Step 4: Analyzes numerical and categorical at the same time - 

describe(trip_clean2$duration)
describe(trip_clean2)

# Check min and max values (outliers)
# Check Distributions (same as before)

# Saving trip_clean2 as an RDS file
saveRDS(trip_clean2, "trip_clean2.rds")
```
Outliers were identified using the equation 1.5xIQR + Q3 for identifying the upper limits and 1.5xIQR - Q1 for identifying the lower limits. There were approximately 65,195 outliers if the upper and lower limits were to be removed. To prevent loss of a massive number of data points the outliers were identified and reassigned to be the upper and lower limits as opposed to removing them entirely. A histogram of duration trip frequency was created to examine the distribution and to check for any extreme skewedness (Figure 2). Using the “describe” function from the “ Hmisc” package a final check of the data was done to ensure outliers had been addressed. After modifying outliers to be either upper or lower limits, the new mean of trip duration was 598.9 seconds. The modified trip data set was named “trip_clean2” and saved as a RDS file for later use.

```{r hist_trip_data, echo=FALSE, warning=FALSE}
hist(trip_clean2$duration, main = "Histogram of Trip Duration", xlab = "Trip Duration in Seconds")  
```
Figure 2: Histogram of trip durations in seconds. Note frequencies at each end of the range are large due to the reassignment of outliers to upper and lower limits.


Exploratory Data Analysis for Weather Data 

First approach to the data 

```{r weather_glimpse, include=FALSE}
#Uploading weather.dataset and assigning to weather_df object
weather_df <- read.csv("weather.csv")

#Overview on variables from each column and few observations
glimpse(weather_df)

#Profiling the data input 
status(weather_df)

#performing necessary transformations before visualization
weather_df_1 <- weather_df %>% 
  #changing date-column from character to as.date type 
  mutate(date = as.POSIXct(date, format="%d/%m/%y")) %>%
  #replacing T-values in precipitation column with 0 
  mutate (precipitation_inches = str_replace(precipitation_inches, pattern="T", replacement="0")) %>% 
  #changing precipitation from character to numeric  
  mutate (precipitation_inches = as.numeric(precipitation_inches)) %>%
  #changing cloud cover variable from character to factor  
  mutate (cloud_cover = as.factor(cloud_cover)) %>%
  #changing events to character type 
  mutate (events = as.character(events)) %>%
  #recoding "" in events to NA 
  mutate (events = na_if(x=events, y="")) %>%
  #changing events to be coded as factor
  mutate (events = as.factor(events)) %>%
  #changing zipcode to be coded as factor
  mutate (zip_code = as.factor(as.character(zip_code))) %>%
  #changing city to be coded as factor 
  mutate (city = as.factor(city)) %>% 
  #changing max_visibility_miles to be coded as numeric 
  mutate (max_visibility_miles = as.numeric(max_visibility_miles)) %>% 
  #changing mean_visibility_miles to be coded as numeric 
  mutate (mean_visibility_miles = as.numeric(mean_visibility_miles)) %>% 
  #changing max_wind_Speed_mph to be coded as numeric 
  mutate (max_wind_Speed_mph = as.numeric(max_wind_Speed_mph)) %>% 
  #changing max_gust_speed_mph to be coded as numeric 
  mutate (max_gust_speed_mph = as.numeric(max_gust_speed_mph)) %>%
  #changing mean_wind_speed_mph to be coded as numeric 
  mutate (mean_wind_speed_mph = as.numeric(mean_wind_speed_mph)) %>% 
  #changing min_visibility_miles to be coded as numeric 
  mutate (min_visibility_miles = as.numeric(min_visibility_miles)) %>%
  #changing max_temperature_f to be coded as numeric 
  mutate (max_temperature_f = as.numeric(max_temperature_f)) %>% 
  #changing mean_temperature_f to be coded as numeric 
  mutate (mean_temperature_f = as.numeric(mean_temperature_f)) %>% 
  #changing min_temperature_f to be coded as numeric 
  mutate (min_temperature_f = as.numeric(min_temperature_f)) 

str(weather_df_1)
```
To initiate our exploration of the weather.csv file, the “glimpse” function from the dplyr package was used to obtain an overview of all the variables from the weather dataset. In this primary step, the following details were noted: 
The date column was formatted in character-form instead of as date form, which necessitated a modification to the latter form. In addition, the max_temperature_f, mean_temperature_f and min_temperature_f variables, along with the max_visibility_miles, mean_visibility_miles, min_visibility_miles variables, and the max_wind_Speed_mph, mean_wind_speed_mph, max_gust_speed_mph variables were provided in integer form. These would need to be coded to numeric form for future analyses, such as correlation plots. Moreover, the precipitation (inches) was incorrectly coded as characters instead of integers, due to the fact that there were a few values coded as “T”. This value encodes “trace” for trace-amounts of precipitation, and would need to be changed to 0. The cloud-cover variable seems to be coded as an integer but could be coded as a factor as there are different categories of cloud-cover. In addition, the events variable seem to be properly coded as characters, however the output also indicated that there are some variables coded as “ “ which would need to be changed to NA. The zipcode variable is also correctly coded as an integer, but should be coded as a factor. Based on this initial examination, the variables were recoded and reformatted before performing any of the future steps of the EDA. 

*Analyzing categorical variables*
The next approach to the exploratory analysis involved performing an assessment of the categorical data through the “freq” function. There were only a few categorical variables assessed, these encompassed the cloud_cover, events, zip_code and city variables and the most relevant plots are shown here. The output revealed that there were 9 levels of the cloud_cover variable, ranging in frequency with 0-cloud cover being the most frequent and 8-cloud_cover category as being the least frequent as shown in Figure 3A. In addition, the events variable indicated that 80.71% (representing 1473 data values) of the data was composed of NA-values, with the next most frequent events composing of rain and fog. Lastly, there were 5 levels associated with the cities, related to the 5 levels of zipcodes, which are evenly distributed in frequency, as shown by Figure 3B. 
```{r weather_categorical, echo=FALSE}
#analyzing categorical data 
#figure out how to 
output_weather <- freq(weather_df_1)
```

Figure 3: Assessment of Categorical Variables. A) Frequency of Weather Events (Left) B) Frequency of Dates for Each City (Right)

*Analyzing numerical variables *
After assessing the categorical variables, the variables remaining were numerical in form, and were thus explored through the plot_num function. For this function, barplots were provided for all the numerical variables, which helped us develop initial insights into each of variables as can be seen in Figure 4. The minimum-visibility (miles), maximum-gust-speed (mph) variables, along with max_gust_speed_mph and precipitation_inches variables show relatively skewed and unbalanced distributions which can be attributed to the presence of outliers that would need to be removed, supporting previous analyses. The remaining numerical variables seem to have a relatively normal distribution, without any discerning outliers. 

```{r figure_4, echo=FALSE}
#analyzing categorical data 
plot_num(weather_df_1)
```
Figure 4: Assessment of Numerical Variables. The minimum-visibility (miles), maximum-gust-speed (mph), max_gust_speed_mph and precipitation_inches variables display skewed-distributions.

After plotting the numerical variables, the profiling-num function was performed to obtain an understanding of each variable’s distribution and range. This function demonstrated that there is a high standard deviation for the max_temperature_f, mean_temperature_f, min_temperature_f, max_wind_Speed_mph and max_gust_speed_mph variables. In addition, the variation coefficient demonstrated that the precipitation_inches variable is associated with more variance as opposed to the remaining variables that are centered around the mean, inferring less accuracy associated with this variable if it were to be chosen as a possible predictor. The skewness metric informs on the measure of asymmetry, and this function demonstrated that the variables of max_visibility_miles, mean_visibility_miles, max_wind_Speed_mph, max_gust_speed_mph and precipitation_inches variables have greater skewness-values and therefore greater likelihood of observing outliers in these variables. The kurtosis variable describes the distribution for the tails, where higher number indicates presence of outliers, and this was demonstrated by the higher values shown for the max_visibility_miles, mean_visibility_miles, max_wind_Speed_mph, max_gust_speed_mph and precipitation_inches variables. There was also a high IQR range for the max_temperature_f, mean_temperature_f, and min_temperature_f variables obtained. 
The describe function was used to obtain an overall overview of both the numerical and categorical variables. The date-column has 144 unique values but 720 dates available, with the remaining 1105 values being missing values and representing 60.5% of the date-data. These values range from 2020-01-10 to 2020-12-12. Since this date-data is being used for combining with the trip-data based on date, values with missing dates will be removed. The max_temperature_f column has 46 unique values, ranging from 50 to 102. For the mean_temperature_f variable, there are 37 distinct values ranging from 44 to 84, and similarly, there are 37 distinct values for the min_temperature_f variable, ranging from 32 to 69. The max_visibility_miles has 9 missing values, and 9 distinct values ranging from 5 to 20. This variable was also shown to have many outliers, which will need to be removed. The related column of mean_visibility_miles has 9 missing values, and 17 distinct values ranging from 4 to 20, the higher values representing outlier-values will also will be removed. The min_visibility_miles variable has 9 missing values and 17 distinct values ranging from 4 to 20, but this column does not have any outliers as shown by previous analyses. The max_wind_Speed_mph variable has no missing values, but 34 distinct values ranging from 4 to 122, and this variable has been noted to contain outliers, which will be removed. The mean_wind_speed_mph variable has no missing values, but 20 distinct values ranging from 0 to 19, but no presence of outliers. The max_gust_speed_mph variable has 451 missing values, and 43 distinct-events, ranging from 6 to 114, and previous analyses indicate this variable has outliers which will be removed. For the precipitation inches variable, there are 74 unique values ranging from 0 to 3.36, but this variable has been noted to contain outlier values, which will be removed. For the cloud-cover variable, there are no missing values and 9 distinct events ranging from 0 to 8, with no discernable outliers according to previous analyses. For the event variable, there are 5 distinct-events however with 1473 missing values. For the zip-code variable, there are 0 missing values but 5 distinct events. This variable is also similar to the output from the city-variable, which retrieved 0 missing values but 5 distinct events, with both of these variables retrieving equivalent proportions for the frequency of each of the values. For the variables with missing values which are the date, max_visibility_miles, mean_visibility_miles, min_visibility_miles, max_gust_speed_mph and events variables, the missing-values were not recoded to 0 or other values such as mean/minimum/maximum as these entries instead represent events where values were simply not observed and recorded, and it would be incorrect to impute values in place of them. 

